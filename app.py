import streamlit as st
import pandas as pd
import google.generativeai as genai
import jieba
from collections import Counter
import io

# ==========================================
# 1. é é¢è¨­å®š
# ==========================================
st.set_page_config(
    page_title="Market Insight Miner",
    page_icon="ğŸ’",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    .stDataFrame {font-size: 14px;}
    [data-testid="stSidebar"] {background-color: #f0f2f6;}
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. å´é‚Šæ¬„è¨­å®š
# ==========================================
with st.sidebar:
    st.title("ğŸ’ Market Miner")
    st.markdown("---")
    
    # å®‰å…¨è¼¸å…¥ Key
    api_key = st.text_input("è«‹è¼¸å…¥ Gemini API Key", type="password", help="æ‚¨çš„ Key ä¸æœƒè¢«å„²å­˜ï¼Œåƒ…ç”¨æ–¼æœ¬æ¬¡é‹ç®—")
    
    if not api_key:
        st.warning("âš ï¸ è«‹è¼¸å…¥é‡‘é‘°ä»¥å•Ÿå‹•")
        st.stop()
    else:
        try:
            genai.configure(api_key=api_key)
            st.success("âœ… AI é€£ç·šæˆåŠŸ")
        except Exception as e:
            st.error(f"é‡‘é‘°éŒ¯èª¤: {e}")
            st.stop()

    st.markdown("---")
    mode = st.radio("åŠŸèƒ½é¸æ“‡ï¼š", ["ğŸŒ± æ¨¡å¼ä¸€ï¼šç¨®å­é—œéµå­—ç”Ÿæˆ", "â›ï¸ æ¨¡å¼äºŒï¼šæ•¸æ“šæŒ–æ˜åˆ†æ"])
    st.markdown("---")
    st.caption("v5.0 Streamlit Edition")

# ==========================================
# 3. æ ¸å¿ƒå‡½æ•¸
# ==========================================
def call_gemini(prompt):
    models = ['gemini-3.0-pro', 'gemini-2.5-pro', 'gemini-2.5-flash', 'gemini-1.5-pro']
    for m in models:
        try:
            model = genai.GenerativeModel(m)
            return model.generate_content(prompt).text
        except: continue
    return "âŒ ç³»çµ±å¿™ç¢Œï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

def clean_google_ads_data(df):
    df.columns = df.columns.str.strip()
    
    # æœå°‹é‡
    search_col = next((c for c in df.columns if 'search' in c.lower() or 'æœå°‹' in c), None)
    if search_col:
        def clean_s(val):
            if pd.isna(val): return 0
            s = str(val).replace(',', '').replace('<', '').replace('>', '').strip()
            if '-' in s:
                try: return (float(s.split('-')[0]) + float(s.split('-')[1])) / 2
                except: return 0
            try: return float(s)
            except: return 0
        df['Avg. monthly searches'] = df[search_col].apply(clean_s)
    else: df['Avg. monthly searches'] = 0

    # æˆé•·ç‡
    yoy_col = next((c for c in df.columns if 'yoy' in c.lower() or 'change' in c.lower() or 'è®ŠåŒ–' in c), None)
    if yoy_col:
        def clean_g(val):
            if pd.isna(val): return 0
            s = str(val).replace('%', '').replace(',', '').replace('+', '').strip()
            if 'âˆ' in s: return 10000
            if '--' in s: return 0
            try: return float(s)
            except: return 0
        df['YoY change'] = df[yoy_col].apply(clean_g)
    else: df['YoY change'] = 0
    
    # ç´…æµ· (High Bid)
    cpc_col = next((c for c in df.columns if ('high' in c.lower() and 'bid' in c.lower()) or 'é«˜ä½' in c), None)
    if cpc_col:
        def clean_price(val):
            if pd.isna(val): return 0
            s = str(val).replace(',', '').replace('NT$', '').replace('$', '').strip()
            if '--' in s: return 0
            try: return float(s)
            except: return 0
        df['Top Page Bid (High)'] = df[cpc_col].apply(clean_price)
    else: df['Top Page Bid (High)'] = 0

    # è—æµ· (Competition)
    comp_col = next((c for c in df.columns if 'index' in c.lower() and 'competition' in c.lower()), None)
    if not comp_col: comp_col = next((c for c in df.columns if 'ç«¶çˆ­' in c and 'ç´¢å¼•' in c), None)
    df['Competition Index'] = pd.to_numeric(df[comp_col], errors='coerce').fillna(50) if comp_col else 50
        
    return df

def analyze_nlp(keywords, top_n=20):
    text = " ".join(keywords.astype(str).tolist())
    words = jieba.cut(text)
    stop_words = {'çš„', 'æ¨è–¦', 'èˆ‡', 'åœ¨', 'æ˜¯', 'æœ‰', 'å’Œ', 'äº†', 'åŠ', ' ', 'ä»€ä¹ˆ', 'ä»€éº¼', 'æ€éº¼', 'å¦‚ä½•', 'å—', 'é£Ÿå“', 'ä¿å¥', 'åƒ¹æ ¼', 'å¤šå°‘', 'éŒ¢'}
    filtered_words = [word for word in words if len(word) > 1 and word not in stop_words]
    return pd.DataFrame(Counter(filtered_words).most_common(top_n), columns=['é—œéµè© (Term)', 'é »æ¬¡ (Freq)'])

# ==========================================
# 4. ä»‹é¢é‚è¼¯
# ==========================================

# --- æ¨¡å¼ä¸€ ---
if mode == "ğŸŒ± æ¨¡å¼ä¸€ï¼šç¨®å­é—œéµå­—ç”Ÿæˆ":
    st.header("ğŸŒ± Google Ads ç¨®å­é—œéµå­—ç”Ÿæˆ")
    st.info("è¼¸å…¥ä¸»é¡Œï¼ŒAI è‡ªå‹•ç”Ÿæˆ 3 çµ„ç­–ç•¥é—œéµå­— (æ¯çµ„ 10 å€‹)ï¼Œçªç ´ Google é™åˆ¶ã€‚")
    
    topic = st.text_input("è«‹è¼¸å…¥ç”¢å“æˆ–ä¸»é¡Œ (ä¾‹å¦‚ï¼šç›Šç”ŸèŒ)", "")
    
    if topic and st.button("ğŸš€ ç”Ÿæˆç­–ç•¥"):
        with st.spinner("AI æ­£åœ¨è¦åŠƒæœå°‹æˆ°è¡“..."):
            prompt = f"""
            ä½¿ç”¨è€…ä¸»é¡Œï¼šã€Œ{topic}ã€ã€‚
            è«‹ç”Ÿæˆ 3 çµ„ Google Keyword Planner å°ˆç”¨çš„ç¨®å­é—œéµå­— (æ¯çµ„åš´æ ¼é™åˆ¶ 10 å€‹)ã€‚
            è«‹ä½¿ç”¨ Markdown æ ¼å¼è¼¸å‡ºï¼Œä¸è¦æœ‰å¤šé¤˜å»¢è©±ã€‚
            
            æ ¼å¼ï¼š
            ### 1. ã€å¸‚å ´å¤§ç›¤çµ„ã€‘(æµé‡å‹)
            (10å€‹å“é¡å¤§è©ï¼Œé€—è™Ÿåˆ†éš”)
            
            ### 2. ã€ç²¾æº–è½‰åŒ–çµ„ã€‘(ç—›é»å‹)
            (10å€‹åŠŸæ•ˆ/å‰¯ä½œç”¨/å•å¥è©ï¼Œé€—è™Ÿåˆ†éš”)
            
            ### 3. ã€ç«¶å“æ””æˆªçµ„ã€‘(è—æµ·å‹)
            (10å€‹ç«¶å“æˆ–æ›¿ä»£æ–¹æ¡ˆè©ï¼Œé€—è™Ÿåˆ†éš”)
            """
            result = call_gemini(prompt)
            st.markdown(result)
            st.success("è«‹è¤‡è£½ä¸Šæ–¹å…¶ä¸­ä¸€çµ„è²¼å…¥ Google Adsã€‚")

# --- æ¨¡å¼äºŒ ---
elif mode == "â›ï¸ æ¨¡å¼äºŒï¼šæ•¸æ“šæŒ–æ˜åˆ†æ":
    st.header("â›ï¸ Google Ads æ•¸æ“šæ·±åº¦æŒ–æ˜")
    st.info("ä¸Šå‚³ CSVï¼Œè‡ªå‹•é€²è¡Œ NLP è©é »åˆ†æèˆ‡äº”ç¶­åº¦æ‹†è§£ã€‚")
    
    uploaded_file = st.file_uploader("ä¸Šå‚³ Keyword Planner CSV", type=['csv'])
    
    if uploaded_file:
        try:
            try: df = pd.read_csv(uploaded_file, header=2, encoding='utf-16', sep='\t')
            except:
                try: df = pd.read_csv(uploaded_file, header=2, encoding='utf-8')
                except: df = pd.read_csv(uploaded_file, header=2, encoding='latin1')

            df = clean_google_ads_data(df)
            df['Avg. monthly searches'] = pd.to_numeric(df['Avg. monthly searches']).fillna(0)

            # è¨ˆç®—æŒ‡æ¨™
            top_volume = df.sort_values('Avg. monthly searches', ascending=False).head(10)
            growth_base = df[df['Avg. monthly searches'] > 50]
            top_growth = growth_base.sort_values('YoY change', ascending=False).head(10)
            top_decline = growth_base.sort_values('YoY change', ascending=True).head(10)
            theme_freq = analyze_nlp(df[df['Avg. monthly searches'] > 10]['Keyword'], top_n=15)
            red_ocean = df.sort_values('Top Page Bid (High)', ascending=False).head(10)
            blue_ocean = df[(df['Avg. monthly searches'] > 100) & (df['Competition Index'] < 30)].sort_values('Avg. monthly searches', ascending=False).head(10)

            # é¡¯ç¤º Tabs
            st.divider()
            t1, t2, t3, t4, t5 = st.tabs(["ğŸ“ˆ å¤§ç›¤", "ğŸš€ æ©Ÿæœƒ", "ğŸ“‰ é¢¨éšª", "ğŸ§  æ¦‚å¿µ", "âš”ï¸ ç´…è—æµ·"])
            
            with t1: st.dataframe(top_volume[['Keyword', 'Avg. monthly searches', 'YoY change']].style.background_gradient(subset=['Avg. monthly searches'], cmap='Greens'), use_container_width=True)
            with t2: st.dataframe(top_growth[['Keyword', 'YoY change', 'Avg. monthly searches']].style.background_gradient(subset=['YoY change'], cmap='Reds'), use_container_width=True)
            with t3: st.dataframe(top_decline[['Keyword', 'YoY change', 'Avg. monthly searches']].style.background_gradient(subset=['YoY change'], cmap='Greys'), use_container_width=True)
            with t4: st.bar_chart(theme_freq.set_index('é—œéµè© (Term)'))
            with t5:
                c1, c2 = st.columns(2)
                with c1: 
                    st.markdown("ğŸ”¥ **ç´…æµ· (é«˜å‡ºåƒ¹)**")
                    st.dataframe(red_ocean[['Keyword', 'Top Page Bid (High)']], use_container_width=True)
                with c2: 
                    st.markdown("ğŸ’§ **è—æµ· (ä½ç«¶çˆ­)**")
                    st.dataframe(blue_ocean[['Keyword', 'Competition Index', 'Avg. monthly searches']], use_container_width=True)

            # AI åˆ†æ
            st.divider()
            if st.button("ğŸ§  å‘¼å« Gemini é€²è¡Œæˆ°ç•¥è§£è®€"):
                with st.spinner("AI é¡§å•æ­£åœ¨åˆ†æä¸­..."):
                    ctx = f"""
                    1.å¤§ç›¤: {top_volume['Keyword'].tolist()}
                    2.æ©Ÿæœƒ: {top_growth['Keyword'].tolist()}
                    3.é¢¨éšª: {top_decline['Keyword'].tolist()}
                    4.æ¦‚å¿µ: {theme_freq.values.tolist()}
                    5.ç´…æµ·: {red_ocean['Keyword'].tolist()}
                    6.è—æµ·: {blue_ocean['Keyword'].tolist()}
                    """
                    prompt = f"""
                    ä½ æ˜¯ä¸€ä½å•†æ¥­åˆ†æå¸«ã€‚è«‹æ ¹æ“šé€™äº”å€‹ç¶­åº¦æ•¸æ“šæ­¸ç´ï¼š
                    {ctx}
                    è«‹å›ç­”ï¼š
                    1. **å¸‚å ´éš±è—å±¬æ€§ï¼Ÿ** (å¾NLPæ¦‚å¿µè©ä¸­ç™¼ç¾äº†ä»€éº¼ç‰¹å¾µï¼Ÿ)
                    2. **æ–°èˆŠå‹¢åŠ›äº¤æ›¿ï¼Ÿ** (ä»€éº¼è¦æ ¼åœ¨å´›èµ· vs æ¶ˆå¤±ï¼Ÿ)
                    3. **ç²åˆ©å»ºè­°ï¼Ÿ** (é¿é–‹ç´…æµ·ï¼Œåˆ‡å…¥å“ªè£¡ï¼Ÿ)
                    """
                    res = call_gemini(prompt)
                    st.markdown("### ğŸ§  Gemini æŒ–æ˜å ±å‘Š")
                    st.markdown(res)

        except Exception as e:
            st.error(f"CSV è§£æå¤±æ•—: {e}")
